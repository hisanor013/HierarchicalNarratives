{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_model  =\"gpt-4-0613\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb086d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ff82e09",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d977fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken \n",
    "import openai\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "########################\n",
    "openai.api_key = \"YOUR-KEY\"\n",
    "########################\n",
    "model = tiktoken.get_encoding(\"cl100k_base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564fc09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d55d6d1",
   "metadata": {},
   "source": [
    "# ChatGPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a461414",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "LOG_FILE = os.path.join(\"log\", \"finance_api_\" +  use_model  + \"_\"+ now.strftime('%Y-%m-%dT%H_%M_%S') + \".log\") \n",
    "\n",
    "if os.path.exists(\"log\") == False:\n",
    "    os.makedirs(\"log\")\n",
    "\n",
    "print(LOG_FILE)\n",
    "\n",
    "def get_completion(messages, model=use_model):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        #response_format={\"type\":\"json_object\"},\n",
    "        response_format={\"type\":\"text\"},\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "DOLLAR_PER_TOKEN = 0.002/1000\n",
    "YEN_PER_DOLLAR= 139.69\n",
    "\n",
    "# トークン数とコストを計算\n",
    "def check_tokens(prompt, model):\n",
    "    tokens = model.encode(prompt)\n",
    "    num_tokens = len(tokens)\n",
    "    cost_dollar = len(tokens)*DOLLAR_PER_TOKEN\n",
    "    cost_yen = len(tokens)*DOLLAR_PER_TOKEN*YEN_PER_DOLLAR\n",
    "    return num_tokens, cost_dollar, cost_yen\n",
    "\n",
    "def load_record(path,record2hantei):\n",
    "\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    out_edges = []\n",
    "    \n",
    "    for kkk in range(len(lines)):\n",
    "        #kkk = 0\n",
    "        data = json.loads(lines[kkk])\n",
    "        answer = data[\"answer\"]\n",
    "        text = data['input']\n",
    "        date = data[\"date\"]\n",
    "        now_future = data[\"type\"]\n",
    "        record = date + \";\" + now_future + \";\" + text\n",
    "        record2hantei.update({record:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a319d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "695e642d",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a099154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "The given text contains information about whether the price of a 40% Stock, 60% Bond Portfolio is expected to move by more than 2% within 5 days, where class 1 denotes a fall, class 2 denotes a rise, and class 0 implies no change (tie), along with the underlying brief reasoning that led the AI to make that decision.\n",
    "Based on this information, analyze the cause-and-effect relationships underlying the AI's decision and explain them in detail. It is possible that multiple cause-and-effect relationships exist within the sentences providing the reasoning. Extract all of these, and create a node list and an edge list. When connecting causes and effects, use \"--*\" for paradoxical connections like \"despite\" or \"but,\" and use \"-->\" for logical connections like \"therefore.\" Also, connect the final formed cause-and-effect relationships with the decision using either \"-->\" or \"--*\" depending on the connection. For the decision nodes, indicate only the numbers representing the decisions (1, 2, or 0).\n",
    "Be sure to output only the answer. Since the output will be processed mechanically, strictly follow the format shown in the example, and do not forget to include connection types (\"-->\" or \"--*\") as well as the nodes representing causes and effects.\n",
    "Additionally, ensure that no phrases that do not exist in the original text are included in the edge list and confirm that the occurrence of phrases not present in the original text is 0.\n",
    "Finally, output the result in JSON format.\n",
    "Example: \n",
    "Input\n",
    "0;Given the mixed market sentiment, slight volatility in interest rates, and decreasing market volatility, the portfolio is likely to experience minor fluctuations.; \n",
    "Output\n",
    "{\n",
    "  \"nodes\": [\"mixed market sentiment\", \"slight volatility in interest rates\", \"decreasing market volatility\", \"portfolio is likely to experience minor fluctuations\", \"0\"],\n",
    "  \"edges\": [\n",
    "    [\"mixed market sentiment\", \"-->\", \"portfolio is likely to experience minor fluctuations\"],\n",
    "    [\"slight volatility in interest rates\", \"-->\", \"portfolio is likely to experience minor fluctuations\"],\n",
    "    [\"decreasing market volatility\", \"-->\", \"portfolio is likely to experience minor fluctuations\"],\n",
    "    [\"portfolio is likely to experience minor fluctuations\", \"-->\", \"0\"]\n",
    "  ]\n",
    "}\n",
    "=====\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f40175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d38b8407",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caadf7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_csv_files(directory, filename=\"df_output.csv\"):\n",
    "    csv_files = []\n",
    "    # Walk through all subdirectories and files\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == filename:\n",
    "                # Join root and file to get full path\n",
    "                csv_files.append(os.path.join(root, file))\n",
    "    return csv_files\n",
    "\n",
    "###########\n",
    "directory_path = '/your/path/gpt-finance'  # Change this to your directory path\n",
    "###########\n",
    "csv_files = find_csv_files(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1afe94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_list = []\n",
    "for i in range(len(csv_files)):\n",
    "    persona = csv_files[i].split(\"/\")[9]\n",
    "    df_tmp = pd.read_csv(csv_files[i])\n",
    "    df_tmp[\"persona\"] = persona\n",
    "    out_list.append(df_tmp)\n",
    "    \n",
    "df = pd.concat(out_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d682745b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "640c67f1",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea74d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "START_FROM_SCRATCH = 1\n",
    "START_INDEX = 0\n",
    "print(START_INDEX)\n",
    "################################################\n",
    "\n",
    "record2hantei = dict()\n",
    "file_list = []\n",
    "\n",
    "if START_FROM_SCRATCH != 1:\n",
    "    for file in file_list:\n",
    "        load_record(file,record2hantei)\n",
    "        \n",
    "print(LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13952256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b7812d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "136ae600",
   "metadata": {},
   "source": [
    "# Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2d01c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that will convert numpy types to native types\n",
    "def convert_to_python_type(obj):\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()  # Convert numpy array to list\n",
    "    else:\n",
    "        raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b39ac9",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9762c247",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "for kkk in range(5):\n",
    "    print(\"TRY: \" + str(kkk) + \", Start \" + str(START_INDEX))\n",
    "    try:\n",
    "        for i in tqdm.tqdm(range(START_INDEX,len(df))):\n",
    "        \n",
    "            prediction = df[\"prediction\"].iloc[i]\n",
    "            text = df[\"reason\"].iloc[i]\n",
    "            target = df[\"TargetPortDailyRtn\"].iloc[i]\n",
    "            date = df[\"Dates\"].iloc[i]\n",
    "            persona  = df[\"persona\"].iloc[i]\n",
    "            t = str(prediction) + \";\" + text\n",
    "            prompt = prompt_template + t \n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\" : \"user\",\n",
    "                    \"content\" : prompt\n",
    "                }\n",
    "            ]\n",
    "            tmp_response1 = get_completion(messages)\n",
    "            num_tokens1, cost_dollar1, cost_yen1 = check_tokens(tmp_response1, model)\n",
    "\n",
    "            result = {\n",
    "                \"index\": i,\n",
    "                \"input\": t,\n",
    "                \"prediction\":prediction,\n",
    "                \"target\":target,\n",
    "                \"date\": date,\n",
    "                \"persona\": persona,\n",
    "                \"cost\":{\n",
    "                    1:{\n",
    "                        \"num_tokens1\":num_tokens1,\n",
    "                        \"cost_dollar1\":cost_dollar1,\n",
    "                        \"cost_yen1\":cost_yen1\n",
    "                    }\n",
    "                },\n",
    "                \"answer\":tmp_response1\n",
    "            }\n",
    "\n",
    "            with open(LOG_FILE, \"a\") as f:\n",
    "                print(json.dumps(result,default=convert_to_python_type), file=f)\n",
    "            START_INDEX = i\n",
    "\n",
    "    except:\n",
    "        START_INDEX = i\n",
    "        time.sleep(5.4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28eb714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59eae44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
