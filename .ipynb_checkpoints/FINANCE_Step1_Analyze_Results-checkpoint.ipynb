{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff8e554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_model = \"finance_gpt4\"\n",
    "# Choose embedding method\n",
    "model_embed = \"use\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff82e09",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8d977fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import jaconv\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "import networkx as nx\n",
    "import unicodedata\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e3a7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_list = glob.glob(\"log/finance_api_gpt-4-0613*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46daadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2c88db0",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c7d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_log(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    out_edges = []\n",
    "    for kkk in range(len(lines)):\n",
    "        #kkk = 6434\n",
    "        data = json.loads(lines[kkk])\n",
    "        answer = data[\"answer\"]\n",
    "                \n",
    "        date = data[\"date\"]\n",
    "        persona = data[\"persona\"]\n",
    "        text = data['input']\n",
    "\n",
    "        try:\n",
    "            if answer.startswith('```json'):\n",
    "                # Strip the markdown code block indicators\n",
    "                answer = answer.strip('```json\\\\n')\n",
    "                # Load the inner JSON\n",
    "                answer_dict = json.loads(answer)\n",
    "                nodes = answer_dict['nodes']\n",
    "                edges = answer_dict['edges']\n",
    "                \n",
    "                #### ADDED ####\n",
    "                edges = list(edges)\n",
    "                ###############\n",
    "\n",
    "                for j in range(len(edges)):\n",
    "                    try:\n",
    "                        if \"-->\" == edges[j][1]:\n",
    "                            out_edges.append([date,text,persona,edges[j][0],\"cause\",edges[j][2]])\n",
    "                        else:\n",
    "                            out_edges.append([date,text,persona,edges[j][0],\"nin\",edges[j][2]])\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "            elif \"\\n}\\n}\" in answer:\n",
    "                answer = answer.replace(\"\\n}\\n}\",\"]\\n}\")\n",
    "                answer_dict = json.loads(answer)\n",
    "\n",
    "                nodes = answer_dict['nodes']\n",
    "                edges = answer_dict['edges']\n",
    "                #### ADDED ####\n",
    "                edges = list(edges)\n",
    "                ###############\n",
    "                \n",
    "                for j in range(len(edges)):\n",
    "                    try:\n",
    "                        if \"-->\" == edges[j][1]:\n",
    "                            out_edges.append([date,text,persona,edges[j][0],\"cause\",edges[j][2]])\n",
    "                        else:\n",
    "                            out_edges.append([date,text,persona,edges[j][0],\"nin\",edges[j][2]])\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "            elif answer.startswith(';\\nOutput'):\n",
    "                cleaned_string = answer.replace(';\\nOutput\\n', '').strip()\n",
    "                answer_dict = json.loads(cleaned_string)\n",
    "                \n",
    "                nodes = answer_dict['nodes']\n",
    "                edges = answer_dict['edges']\n",
    "                #### ADDED ####\n",
    "                edges = list(edges)\n",
    "                ###############\n",
    "                \n",
    "                for j in range(len(edges)):\n",
    "                    try:\n",
    "                        if \"-->\" == edges[j][1]:\n",
    "                            out_edges.append([date,text,persona,edges[j][0],\"cause\",edges[j][2]])\n",
    "                        else:\n",
    "                            out_edges.append([date,text,persona,edges[j][0],\"nin\",edges[j][2]])\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "            elif answer.startswith('This could lead to a fall in the portfolio\\'s value.;\\nOutput'):\n",
    "                cleaned_string = answer.replace('This could lead to a fall in the portfolio\\'s value.;\\nOutput\\n', '').strip()\n",
    "                answer_dict = json.loads(cleaned_string)\n",
    "                \n",
    "                nodes = answer_dict['nodes']\n",
    "                edges = answer_dict['edges']\n",
    "                #### ADDED ####\n",
    "                edges = list(edges)\n",
    "                ###############\n",
    "                \n",
    "                for j in range(len(edges)):\n",
    "                    try:\n",
    "                        if \"-->\" == edges[j][1]:\n",
    "                            #tmp = edges[j].split(\"-->\")\n",
    "                            out_edges.append([date,text,persona,edges[j][0],\"cause\",edges[j][2]])\n",
    "                        else:\n",
    "                            out_edges.append([date,text,persona,edges[j][0],\"nin\",edges[j][2]])\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "            elif answer.startswith('This is expected to put downward pressure on the portfolio.; \\nOutput'):\n",
    "                cleaned_string = answer.replace('This is expected to put downward pressure on the portfolio.; \\nOutput\\n', '').strip()\n",
    "                answer_dict = json.loads(cleaned_string)\n",
    "                \n",
    "                nodes = answer_dict['nodes']\n",
    "                edges = answer_dict['edges']\n",
    "                #### ADDED ####\n",
    "                edges = list(edges)\n",
    "                ###############\n",
    "                \n",
    "                for j in range(len(edges)):\n",
    "                    try:\n",
    "                        if \"-->\" == edges[j][1]:\n",
    "                            #tmp = edges[j].split(\"-->\")\n",
    "                            out_edges.append([date,text,persona,edges[j][0],\"cause\",edges[j][2]])\n",
    "                        else:\n",
    "                            out_edges.append([date,text,persona,edges[j][0],\"nin\",edges[j][2]])\n",
    "                    except:\n",
    "                        pass\n",
    "                              \n",
    "            elif answer.startswith('; \\nOutput'):\n",
    "                cleaned_string = answer.replace('; \\nOutput\\n', '').strip()\n",
    "                answer_dict = json.loads(cleaned_string)\n",
    "                \n",
    "                nodes = answer_dict['nodes']\n",
    "                edges = answer_dict['edges']\n",
    "                #### ADDED ####\n",
    "                edges = list(edges)\n",
    "                ###############\n",
    "                \n",
    "                for j in range(len(edges)):\n",
    "                    try:\n",
    "                        if \"-->\" == edges[j][1]:\n",
    "                            out_edges.append([date,text,persona,edges[j][0],\"cause\",edges[j][2]])\n",
    "                        else:\n",
    "                            out_edges.append([date,text,persona,edges[j][0],\"nin\",edges[j][2]])\n",
    "                    except:\n",
    "                        pass\n",
    "                                        \n",
    "            elif answer.startswith('Output'):\n",
    "                cleaned_string = answer.replace('Output\\n', '').strip()\n",
    "                answer_dict = json.loads(cleaned_string)\n",
    "                \n",
    "                nodes = answer_dict['nodes']\n",
    "                edges = answer_dict['edges']\n",
    "                #### ADDED ####\n",
    "                edges = list(edges)\n",
    "                ###############\n",
    "                \n",
    "                for j in range(len(edges)):\n",
    "                    try:\n",
    "                        if \"-->\" == edges[j][1]:\n",
    "                            out_edges.append([date,text,persona,edges[j][0],\"cause\",edges[j][2]])\n",
    "                        else:\n",
    "                            out_edges.append([date,text,persona,edges[j][0],\"nin\",edges[j][2]])\n",
    "                    except:\n",
    "                        pass           \n",
    "                    \n",
    "            else:\n",
    "                #print(\"yes\")\n",
    "                answer_dict = json.loads(answer)\n",
    "\n",
    "                nodes = answer_dict['nodes']\n",
    "                edges = answer_dict['edges']\n",
    "                #### ADDED ####\n",
    "                edges = list(edges)\n",
    "                ###############\n",
    "                \n",
    "                for j in range(len(edges)):\n",
    "                    try:\n",
    "                        if \"-->\" == edges[j][1]:\n",
    "                            #tmp = edges[j].split(\"-->\")\n",
    "                            out_edges.append([date,text,persona,edges[j][0],\"cause\",edges[j][2]])\n",
    "                        else:\n",
    "                            out_edges.append([date,text,persona,edges[j][0],\"nin\",edges[j][2]])\n",
    "                    except:\n",
    "                        pass\n",
    "        except:\n",
    "            print(kkk)\n",
    "    return out_edges\n",
    "\n",
    "\n",
    "\n",
    "def convert_numbers(df):\n",
    "    # Function to check if the value is numeric (float or int)\n",
    "    def is_number(x):\n",
    "        try:\n",
    "            float(x)  # Type-casting to float to check for numeric\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    # Applymap to check each element if it's numeric and then convert\n",
    "    df[\"source\"] = df[\"source\"].apply(lambda x: str(int(float(x))) if is_number(x) else x)\n",
    "    df[\"target\"] = df[\"target\"].apply(lambda x: str(int(float(x))) if is_number(x) else x)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_full_width_numeral_to_half_width(element):\n",
    "    if isinstance(element, str):\n",
    "        # Normalize element to half-width if it contains full-width numerals\n",
    "        return ''.join(unicodedata.normalize('NFKC', char) if '\\uff10' <= char <= '\\uff19' else char for char in element)\n",
    "    return element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a19cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc300d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b27ea83d",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99878c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we loaded: 40375\n"
     ]
    }
   ],
   "source": [
    "list_df = []\n",
    "for i in range(len(log_list)):\n",
    "    path = log_list[i]\n",
    "    out_edges = read_log(path)\n",
    "    df_edges = pd.DataFrame(out_edges)\n",
    "    df_edges.columns = [\"date\",\"text\",\"persona\",\"source\",\"relation\",\"target\"]\n",
    "    df_edges[\"date\"] = pd.to_datetime(df_edges[\"date\"])\n",
    "    list_df.append(df_edges)\n",
    "    \n",
    "df_edges = pd.concat(list_df)\n",
    "print(\"What we loaded: \" + str(len(df_edges)))\n",
    "\n",
    "df_edges[\"source\"] = df_edges[\"source\"].astype(str)\n",
    "df_edges[\"target\"] = df_edges[\"target\"].astype(str)\n",
    "df_edges = df_edges.applymap(convert_full_width_numeral_to_half_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a8132d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0beac0d",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc6117e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short_term\n",
      "1;Rising interest rates and VIX suggest market uncertainty, while a stronger dollar could pressure exports, potentially impacting the portfolio negatively.\n"
     ]
    }
   ],
   "source": [
    "i = 128\n",
    "print(df_edges[\"persona\"].iloc[i])\n",
    "print(df_edges[\"text\"].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db11ef2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_term\n",
      "1;Given the increased volatility, narrowing interest rate spread, and drop in stock futures, a decline is anticipated.\n"
     ]
    }
   ],
   "source": [
    "i = -316\n",
    "print(df_edges[\"persona\"].iloc[i])\n",
    "print(df_edges[\"text\"].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f421663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = (df_edges[\"source\"] != df_edges[\"target\"]) & (df_edges[\"relation\"] == \"cause\")\n",
    "df_edges = df_edges.loc[cond].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97278d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9139b9a",
   "metadata": {},
   "source": [
    "# Basic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75f69a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relation\n",
       "cause    37354\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tree numbers as numbers\n",
    "df_edges[\"relation\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac18f154",
   "metadata": {},
   "source": [
    "# Phrase Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b03a75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 12:59:12.916278: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-25 12:59:14.262486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-10-25 12:59:17.821095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 23659 MB memory:  -> device: 0, name: Quadro P6000, pci bus id: 0000:37:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# THIS MODEL MIGHT NOT BE SUITABLE FOR PYTHON 3.10 and LATER\n",
    "if model_embed == \"use\":\n",
    "    import tensorflow\n",
    "    import tensorflow_hub as hub\n",
    "    import tensorflow_text\n",
    "    embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")\n",
    "    \n",
    "else:\n",
    "    from transformers import BertModel, BertTokenizer\n",
    "    import torch\n",
    "\n",
    "    def load_model_and_tokenizer():\n",
    "        # Load tokenizer and model from Hugging Face Hub\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "        model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "        return tokenizer, model\n",
    "\n",
    "    def get_embeddings(texts, tokenizer, model):\n",
    "        # Tokenize input texts and prepare input tensors\n",
    "        encoded_input = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "        # Move tensors to the same device as the model\n",
    "        input_ids = encoded_input['input_ids']\n",
    "\n",
    "        with torch.no_grad():  # Do not compute gradients\n",
    "            # Forward pass, get hidden states\n",
    "            output = model(input_ids)\n",
    "            # We take the embeddings from the last hidden state\n",
    "            embeddings = output.last_hidden_state[:, 0, :]\n",
    "        return embeddings\n",
    "\n",
    "    tokenizer, model = load_model_and_tokenizer()\n",
    "    # Get embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba1570c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89fba32d",
   "metadata": {},
   "source": [
    "# Create Node List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "312e7333",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(set(df_edges[\"source\"]))\n",
    "nodes.extend(list(set(df_edges[\"target\"])))\n",
    "nodes = list(set(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eba0d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_embed == \"use\":\n",
    "    # USE\n",
    "    num_bunkatsu = 1000\n",
    "    list_nodes = []\n",
    "    for i in range(int( len(nodes) / num_bunkatsu) + 1):\n",
    "        start = i*num_bunkatsu\n",
    "        owari = (i+1)*num_bunkatsu\n",
    "        #print(start,owari)\n",
    "        list_nodes.append(embed(nodes[start:owari]))\n",
    "    nodes_emb = np.concatenate(list_nodes)\n",
    "else:\n",
    "    # BERT\n",
    "    \n",
    "    num_bunkatsu = 1000\n",
    "    list_nodes = []\n",
    "    for i in range(int( len(nodes) / num_bunkatsu) + 1):\n",
    "        start = i*num_bunkatsu\n",
    "        owari = (i+1)*num_bunkatsu\n",
    "        #print(start,owari)\n",
    "        \n",
    "        list_nodes.append(get_embeddings(nodes[start:owari], tokenizer, model))\n",
    "    nodes_emb = np.concatenate(list_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a8d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d67467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "180222f7",
   "metadata": {},
   "source": [
    "# Clustring using DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aef9680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.23 s, sys: 3.05 s, total: 12.3 s\n",
      "Wall time: 949 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Hyper parameters\n",
    "if model_embed == \"use\":\n",
    "    eps = 0.25\n",
    "    min_samples= 2\n",
    "else:\n",
    "    eps = 2.5\n",
    "    min_samples= 2\n",
    "clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(nodes_emb) # debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f87988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bb1c6eb",
   "metadata": {},
   "source": [
    "# Deduplicate nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f05a8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to clusters that are not treated as outliers (-1)\n",
    "df_nodes = pd.DataFrame({\"node\":nodes,\"label\":clustering.labels_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d1939b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec83c63c",
   "metadata": {},
   "source": [
    "# For strings with length 1. Replace numbers to DBSCAN LABEL -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15d0b2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -1\n",
      "2 -1\n",
      "0 -1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_nodes)):\n",
    "    if len(df_nodes[\"node\"].iloc[i]) == 1:\n",
    "        df_nodes.loc[i,\"label\"] = -1\n",
    "        print(df_nodes[\"node\"].iloc[i],df_nodes[\"label\"].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b01d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67c8449f",
   "metadata": {},
   "source": [
    "# Unify non -1 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab1dba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find representative node name\n",
    "df_nodes.sort_values(by=\"label\",ascending=True,inplace=True)\n",
    "df_nodes[\"new_node\"] = df_nodes[\"node\"]\n",
    "df_new_nodes = df_nodes.drop_duplicates([\"label\"],keep=\"first\").copy()\n",
    "\n",
    "# Get rid of single cluster\n",
    "cond = df_new_nodes[\"label\"] != -1\n",
    "df_new_nodes = df_new_nodes.loc[cond].copy()\n",
    "\n",
    "# Create Dictionary that maps label to node name\n",
    "label2node = dict()\n",
    "for i in range(len(df_new_nodes)):\n",
    "    label = df_new_nodes[\"label\"].iloc[i]\n",
    "    node = df_new_nodes[\"new_node\"].iloc[i]\n",
    "    label2node.update({label:node})\n",
    "    \n",
    "# Create\n",
    "df_nodes[\"new_node\"] = df_nodes[\"label\"].map(label2node).fillna(df_nodes[\"node\"])\n",
    "node2new_node = dict()\n",
    "for i in range(len(df_nodes)):\n",
    "    node = df_nodes[\"node\"].iloc[i]\n",
    "    new_node = df_nodes[\"new_node\"].iloc[i]\n",
    "    node2new_node.update({node:new_node})\n",
    "    \n",
    "# Create replaced edgelist\n",
    "df_edges_replaced = df_edges.copy()\n",
    "df_edges_replaced[\"source\"] = df_edges[\"source\"].map(node2new_node)\n",
    "df_edges_replaced[\"target\"] = df_edges[\"target\"].map(node2new_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a6c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c0c40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da8f3db7",
   "metadata": {},
   "source": [
    "# This is the result used in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf9882e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.896271627000244\n",
      "0.8528957842579806\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>share_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>1</td>\n",
       "      <td>4.898059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>increasing interest rate spread</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>2.168792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>portfolio could face downward pressure</td>\n",
       "      <td>1</td>\n",
       "      <td>1.998213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>increased market volatility</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>1.770774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>increasing interest rate spread</td>\n",
       "      <td>portfolio could face downward pressure</td>\n",
       "      <td>1.299651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Downward trend in portfolio and futures</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>0.990984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yield curve flattening</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>0.958492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>potential for growth</td>\n",
       "      <td>2</td>\n",
       "      <td>0.852896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>general downtrend in the portfolio and futures</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>0.747299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>increased market volatility</td>\n",
       "      <td>portfolio could face downward pressure</td>\n",
       "      <td>0.731054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>increasing volatility</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>0.666071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fluctuating interest rates</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>0.471123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stronger dollar</td>\n",
       "      <td>portfolio could face downward pressure</td>\n",
       "      <td>0.438632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>strengthening dollar</td>\n",
       "      <td>portfolio could face downward pressure</td>\n",
       "      <td>0.430509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stronger dollar</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>0.430509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            source  \\\n",
       "0                         a decline is anticipated   \n",
       "1                  increasing interest rate spread   \n",
       "2           portfolio could face downward pressure   \n",
       "3                      increased market volatility   \n",
       "4                  increasing interest rate spread   \n",
       "5          Downward trend in portfolio and futures   \n",
       "6                           yield curve flattening   \n",
       "7                             potential for growth   \n",
       "8   general downtrend in the portfolio and futures   \n",
       "9                      increased market volatility   \n",
       "10                           increasing volatility   \n",
       "11                      fluctuating interest rates   \n",
       "12                                 stronger dollar   \n",
       "13                            strengthening dollar   \n",
       "14                                 stronger dollar   \n",
       "\n",
       "                                    target  share_value  \n",
       "0                                        1     4.898059  \n",
       "1                 a decline is anticipated     2.168792  \n",
       "2                                        1     1.998213  \n",
       "3                 a decline is anticipated     1.770774  \n",
       "4   portfolio could face downward pressure     1.299651  \n",
       "5                 a decline is anticipated     0.990984  \n",
       "6                 a decline is anticipated     0.958492  \n",
       "7                                        2     0.852896  \n",
       "8                 a decline is anticipated     0.747299  \n",
       "9   portfolio could face downward pressure     0.731054  \n",
       "10                a decline is anticipated     0.666071  \n",
       "11                a decline is anticipated     0.471123  \n",
       "12  portfolio could face downward pressure     0.438632  \n",
       "13  portfolio could face downward pressure     0.430509  \n",
       "14                a decline is anticipated     0.430509  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond = df_edges_replaced[\"persona\"] == \"short_term\"\n",
    "df_short = df_edges_replaced[cond]\n",
    "\n",
    "# Counting the occurrences of each unique pair (source, target)\n",
    "df_short_counts = df_short[[\"source\", \"target\"]].value_counts().reset_index(name=\"count\")\n",
    "\n",
    "# Calculating the share value by dividing the counts by the length of df_long\n",
    "df_short_counts[\"share_value\"] = df_short_counts[\"count\"] / len(df_short) * 100\n",
    "\n",
    "# Showing the top 20 rows\n",
    "df_short_top = df_short_counts[[\"source\", \"target\", \"share_value\"]].head(15)\n",
    "\n",
    "print(sum(df_short_top[\"share_value\"][df_short_top[\"target\"] == \"1\"]))\n",
    "\n",
    "print(sum(df_short_top[\"share_value\"][df_short_top[\"target\"] == \"2\"]))\n",
    "\n",
    "# Display the result\n",
    "df_short_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14532fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.725285171102662\n",
      "0.7921419518377694\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>share_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>1</td>\n",
       "      <td>3.984474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>increasing interest rate spread</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>2.122940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>increased market volatility</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>1.956591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>portfolio could face downward pressure</td>\n",
       "      <td>1</td>\n",
       "      <td>1.314956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yield curve flattening</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>0.942649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>increasing interest rate spread</td>\n",
       "      <td>portfolio could face downward pressure</td>\n",
       "      <td>0.918885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Downward trend in portfolio and futures</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>0.839670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>potential for growth</td>\n",
       "      <td>2</td>\n",
       "      <td>0.792142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>decline in the portfolio is anticipated</td>\n",
       "      <td>1</td>\n",
       "      <td>0.784221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>general downtrend in the portfolio and futures</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>0.720849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a decline in the portfolio price is anticipated</td>\n",
       "      <td>1</td>\n",
       "      <td>0.641635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>increased market volatility</td>\n",
       "      <td>portfolio could face downward pressure</td>\n",
       "      <td>0.578264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>increasing interest rate spread</td>\n",
       "      <td>a decline in the portfolio price is anticipated</td>\n",
       "      <td>0.483207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>increased market volatility</td>\n",
       "      <td>decline in the portfolio is anticipated</td>\n",
       "      <td>0.451521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>general downward trend in the portfolio</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>0.443599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             source  \\\n",
       "0                          a decline is anticipated   \n",
       "1                   increasing interest rate spread   \n",
       "2                       increased market volatility   \n",
       "3            portfolio could face downward pressure   \n",
       "4                            yield curve flattening   \n",
       "5                   increasing interest rate spread   \n",
       "6           Downward trend in portfolio and futures   \n",
       "7                              potential for growth   \n",
       "8           decline in the portfolio is anticipated   \n",
       "9    general downtrend in the portfolio and futures   \n",
       "10  a decline in the portfolio price is anticipated   \n",
       "11                      increased market volatility   \n",
       "12                  increasing interest rate spread   \n",
       "13                      increased market volatility   \n",
       "14          general downward trend in the portfolio   \n",
       "\n",
       "                                             target  share_value  \n",
       "0                                                 1     3.984474  \n",
       "1                          a decline is anticipated     2.122940  \n",
       "2                          a decline is anticipated     1.956591  \n",
       "3                                                 1     1.314956  \n",
       "4                          a decline is anticipated     0.942649  \n",
       "5            portfolio could face downward pressure     0.918885  \n",
       "6                          a decline is anticipated     0.839670  \n",
       "7                                                 2     0.792142  \n",
       "8                                                 1     0.784221  \n",
       "9                          a decline is anticipated     0.720849  \n",
       "10                                                1     0.641635  \n",
       "11           portfolio could face downward pressure     0.578264  \n",
       "12  a decline in the portfolio price is anticipated     0.483207  \n",
       "13          decline in the portfolio is anticipated     0.451521  \n",
       "14                         a decline is anticipated     0.443599  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond = df_edges_replaced[\"persona\"] == \"medium_term\"\n",
    "df_medium = df_edges_replaced[cond]\n",
    "\n",
    "# Counting the occurrences of each unique pair (source, target)\n",
    "df_medium_counts = df_medium[[\"source\", \"target\"]].value_counts().reset_index(name=\"count\")\n",
    "\n",
    "# Calculating the share value by dividing the counts by the length of df_long\n",
    "df_medium_counts[\"share_value\"] = df_medium_counts[\"count\"] / len(df_medium) * 100\n",
    "\n",
    "# Showing the top 20 rows\n",
    "df_medium_top = df_medium_counts[[\"source\", \"target\", \"share_value\"]].head(15)\n",
    "\n",
    "print(sum(df_medium_top[\"share_value\"][df_medium_top[\"target\"] == \"1\"]))\n",
    "\n",
    "print(sum(df_medium_top[\"share_value\"][df_medium_top[\"target\"] == \"2\"]))\n",
    "\n",
    "\n",
    "# Display the result\n",
    "df_medium_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7498b3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.53989854255576\n",
      "1.473548594894919\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>share_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>1</td>\n",
       "      <td>4.275707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>increasing interest rate spread</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>2.004992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>increased market volatility</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>1.860053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>potential for growth</td>\n",
       "      <td>2</td>\n",
       "      <td>1.103148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yield curve flattening</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>1.087044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>general downtrend in the portfolio and futures</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>0.893792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>portfolio could face downward pressure</td>\n",
       "      <td>1</td>\n",
       "      <td>0.885740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Downward trend in portfolio and futures</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>0.644174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>increasing interest rate spread</td>\n",
       "      <td>portfolio could face downward pressure</td>\n",
       "      <td>0.611966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>major price movement is not anticipated</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>increasing volatility</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>0.499235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>steepening yield curve</td>\n",
       "      <td>potential for growth</td>\n",
       "      <td>0.491183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>decline in the portfolio is anticipated</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>potential portfolio growth</td>\n",
       "      <td>2</td>\n",
       "      <td>0.370400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fluctuating interest rates</td>\n",
       "      <td>a decline is anticipated</td>\n",
       "      <td>0.362348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            source  \\\n",
       "0                         a decline is anticipated   \n",
       "1                  increasing interest rate spread   \n",
       "2                      increased market volatility   \n",
       "3                             potential for growth   \n",
       "4                           yield curve flattening   \n",
       "5   general downtrend in the portfolio and futures   \n",
       "6           portfolio could face downward pressure   \n",
       "7          Downward trend in portfolio and futures   \n",
       "8                  increasing interest rate spread   \n",
       "9          major price movement is not anticipated   \n",
       "10                           increasing volatility   \n",
       "11                          steepening yield curve   \n",
       "12         decline in the portfolio is anticipated   \n",
       "13                      potential portfolio growth   \n",
       "14                      fluctuating interest rates   \n",
       "\n",
       "                                    target  share_value  \n",
       "0                                        1     4.275707  \n",
       "1                 a decline is anticipated     2.004992  \n",
       "2                 a decline is anticipated     1.860053  \n",
       "3                                        2     1.103148  \n",
       "4                 a decline is anticipated     1.087044  \n",
       "5                 a decline is anticipated     0.893792  \n",
       "6                                        1     0.885740  \n",
       "7                 a decline is anticipated     0.644174  \n",
       "8   portfolio could face downward pressure     0.611966  \n",
       "9                                        0     0.595861  \n",
       "10                a decline is anticipated     0.499235  \n",
       "11                    potential for growth     0.491183  \n",
       "12                                       1     0.378452  \n",
       "13                                       2     0.370400  \n",
       "14                a decline is anticipated     0.362348  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond = df_edges_replaced[\"persona\"] == \"long_term\"\n",
    "df_long = df_edges_replaced[cond]\n",
    "\n",
    "# Counting the occurrences of each unique pair (source, target)\n",
    "df_long_counts = df_long[[\"source\", \"target\"]].value_counts().reset_index(name=\"count\")\n",
    "\n",
    "# Calculating the share value by dividing the counts by the length of df_long\n",
    "df_long_counts[\"share_value\"] = df_long_counts[\"count\"] / len(df_long) * 100\n",
    "\n",
    "# Showing the top 20 rows\n",
    "df_long_top = df_long_counts[[\"source\", \"target\", \"share_value\"]].head(15)\n",
    "\n",
    "print(sum(df_long_top[\"share_value\"][df_long_top[\"target\"] == \"1\"]))\n",
    "\n",
    "print(sum(df_long_top[\"share_value\"][df_long_top[\"target\"] == \"2\"]))\n",
    "\n",
    "# Display the result\n",
    "df_long_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38bcfbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a0c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a02ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcf5ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e7b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc0925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f1f81e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
